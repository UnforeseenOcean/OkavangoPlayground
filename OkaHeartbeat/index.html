<html>
<head>
  <script language="javascript" type="text/javascript" src="p5.js"></script>
  <script language="javascript" type="text/javascript" src="p5.sound.js"></script>
  <script language="javascript" type="text/javascript" src="p5.dom.js"></script>
  <script language="javascript" type="text/javascript" src="moment.js"></script>
  <script language="javascript" type="text/javascript" src="moment-timezone.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
  <script language="javascript" type="text/javascript" src="sketch.js"></script>
  

  <style> 
    body {
      padding: 0;
      margin: 0;
      font-family: "jaf-bernino-sans","Lucida Grande","Lucida Sans Unicode","Lucida Sans",Geneva,Verdana,sans-serif;
      letter-spacing: -0.02em;
      font-weight: 400;
      font-style: normal;
      text-rendering: optimizeLegibility;
      -webkit-font-smoothing: antialiased;
      -moz-osx-font-smoothing: grayscale;
      -moz-font-feature-settings: "liga" on;
      color: rgba(0,0,0,0.8);
      font-size: 18px;
      line-height: 1.4;
    } 
    .graf {
      width:65%;
      margin:25px;
      margin:auto;
    }
    #header {
      /*background-image: url("img/heartHeader.png");*/
      background-size: cover;
      width:100%;
      height:350px;
    }
    #closing {
      font-size:14px;
    }
    hr.section-divider {
      display: block;
      width: 100px;
      margin: 51px auto 41px auto;
      border: 0;
      border-top: 1px solid rgba(0,0,0,0.15);
    }
    p {
      margin-bottom: 30px;
    }
    a {
      color: inherit;
      text-decoration: underline;
    }
    h2 {
      font-family: "jaf-bernino-sans","Lucida Grande","Lucida Sans Unicode","Lucida Sans",Geneva,Verdana,sans-serif;
      letter-spacing: -0.02em;
      font-weight: 700;
      font-style: normal;
      font-size: 36px;
      margin-left: -1.8px;
      line-height: 1.2;
      margin-top: 40px;
      margin-bottom: 4px;
      color: rgba(0,0,0,0.8);
    }

    #title {
      position: relative;
      top: 50%;
      transform: translateY(-50%);
    }

    #header {
      margin-bottom: 0px;
    }

    #header h2 {
      color:#000;
      width:525px;
      margin:auto;
      vertical-align: middle;
    }
    #header h3 {
      margin:auto;
      vertical-align: middle;
      width:525px;
    }
    #closing h2 {
      font-size:24px;
    }

    #pathMarker {
      display:block;
      position:relative;
      width:20px;
      height:20px;
      background-color:#FF0000;
      visibility: hidden;
    }
  

  </style>
</head>

<body>
  <div id="header">
    <div id="title">
     <h2>Open Story + Open Data</h2>
     <h3>Heartbeats, hippopotami, and threading human experience into datasets.</h3>
    </div>
  </div>
  <div id="pathHolder"></div>
  <div id="introText" class="graf">
  
  <p>
 On May 17th, a small team of researchers and Ba'Yei polers set out to explore the Okavango Delta's catchment from top to bottom. By the time the team on the water pulls their boats up into the sands of the Kalahari at the end of August, the river will have taken them over 2,000km and it will have been more than 100 days since their launch in the Angolan highlands. They will have eaten more than a thousand kilograms of beans, swatted a small army of mosquitos, and threaded their narrow boats through dozens of pods of angry hippopotami. They also will have collected a lot of data, all of which is freely available through an open API:
</p>
<p>
  <a href="http://intotheokavango.org/api/features/viz?FeatureType=sighting&limit=10000&order=descending&expedition=okavango_15">7,777 wildlife sightings</a>, <a href="http://intotheokavango.org/api/features/?FeatureType=sensor&limit=100&order=descending&expedition=okavango_15">17,822 sensor readings</a>, <a href="http://intotheokavango.org/api/features/?FeatureType=image&limit=100&order=descending&expedition=okavango_15">2,042 images</a>, <a href="http://intotheokavango.org/api/features/?FeatureType=ambit_geo&limit=100&order=descending&expedition=okavango_15">105,566 GPS points</a>, and <a href="http://intotheokavango.org/api/features/?FeatureType=ambit_hr&limit=1&order=descending&expedition=okavango_15">3.1 million heart beats</a> so far.
</p>
<p>
But what good is all of this open data without open story?
</p>
<br>
<p>
The sound you're hearing in the background (double check that your speakers are on) is a sonification of expedition leader Steve Boyes' heartbeat from Saturday, July 11th, at around 10:58am. He's just about to be attacked by a three tonne hippopotamus.
</p>
<br>
<p>
  All data encode something. In this case, a set of about 600 numbers encode Steve's harrowing experience on the Cuito River:

  <blockquote><em>
  <p>
  "The front tusks pierced the hull near my left foot and flipped the mokoro over in a single push. Capsized, we were now both in the water on top of the hippo. My first thought was get my legs out of the water. I met Giles on top of the overturned hull. I hear my brother, Chris, shout.
  </p>
  <p>
  "Swim!!"
  </p>
  <p>
  We instantly slip into the water and make for the bank, frantically swimming like no one taught us how. I have never stressed, raced and imagined so much. Seconds of frenzy that I will never forget. We were convinced the follow-up rush and bite was coming. Giles touches my leg and my heart stops beating. The current was taking us and the bank seems further away. Suddenly it was there. Slippery and steep."
  </p>
  </em>
  </blockquote>
<p>
  A typical way to decode the data, to retrieve the experience from the numbers, is through visualization. The graph below shows all of Steve's heartbeats from June 21st: 35 thousand of them. If you click and drag on it to select the bright pink stripe of data that we just heard, beside the white line, you'll be able to see this urgent sequence more closely. You'll also be able to move your mouse to compare the sound of the peak heart rate with some of the calmer moments before and after. Go ahead and do it.
</p>

  </div>

  </p>

  <div id="graph"></div>

  <div id="bottomText" class="graf">
  
<p>
  This data shows us a lot about that day: the duration, the pattern of activity, the maxima and minima. But what it doesn't implicitly give us is narrative. This is because data, in itself, holds no story at all. We can build scaffolding for it by visualizing (or sonifying, or performing) data, but the story itself only manifests when a human (ie. you) looks at our graph.
</p>

<p>
  Very few Open Data releases make any attempt to foster narrative. The datasets might be fascinating, the APIs usable; but without any structure for story, it's hard to make anything with. It's the digital equivalent of a pile of free IKEA parts, kicked out to the curb with no instructions.
</p>

<p>
With Into the Okavango, we set out to make the expedition both Open Data and Open Story. Here are our three guiding principles:
</p>

<h2> 1. Make it easy to put the data in context</h2>

<p>
Wherever possible, we've endeavored to provide framing for the data that we release. For a simple example of this we can look at the visualization and map views in our API. Using small variations of the same URL, people can download sightings as raw data, or see the results on a map, or as a graph:
</p>

<p>
<a href="http://intotheokavango.org/api/features/?FeatureType=sighting&expedition=okavango_15&Taxonomy.Order=Osteoglossiformes">http://intotheokavango.org/api/features/?FeatureType=sighting&expedition=okavango_15&Taxonomy.Order=Osteoglossiformes</a>
</p>

<p>
<a href="http://intotheokavango.org/api/features/viz?FeatureType=sighting&expedition=okavango_15&Taxonomy.Order=Osteoglossiformes">http://intotheokavango.org/api/features/viz?FeatureType=sighting&expedition=okavango_15&Taxonomy.Order=Osteoglossiformes</a>
</p>

<p>
<a href="http://intotheokavango.org/api/features/map?FeatureType=sighting&expedition=okavango_15&Taxonomy.Order=Osteoglossiformes">http://intotheokavango.org/api/features/map?FeatureType=sighting&expedition=okavango_15&Taxonomy.Order=Osteoglossiformes</a>
</p>

<h2>2. Facilitate broad engagement</h2>
<p>
  All of us who release Open Data have a fantasy audience, a group of JSON-savvy enthusiasts who are waiting to spend their evenings and weekends making fascinating things with our datasets. But any other interested parties are usually blocked at the door, through a combination of obfuscation and politics. With ItO, we've tried to provide simple access points to data that anyone can use. We're also releasing samples and source code on GitHub, and are working to create a series of curricula for use by students and teachers.
</p>

<p>
  I often describe APIs as bridges. I think one of the issues we have right now is that these bridges are being built for heavy machinery, and not for foot traffic. What does an API look like that is a pedestrian bridge?
</p>

<h2>3. Frame the data with human experience</h2>
<p>
  Science doesn't just happen. Humans do science. Humans with real lives, real foibles, real blistered feet. As much as possible, we've tried to pair data about human experience (tweets, photographs, sound recordings, Medium posts) alongside the core research data. And we've kept this human data in the same format as the science data (GeoJSON) so that it's easy to thread one data set through another.
</p>

<p>
As you were looking at Steve's heart rate graph you might have noticed a second spike, about an hour after the hippo attack. This confused me; from the GPS points I knew they had continued down the river after only a short break. Had there been another scare? As I was drafting this post, I sent him an e-mail, asking what he thought could have caused that second elevation in heart rate. A few days passed.
</p>

<p>
Finally, an e-mail arrived. After the attack, Steve told me, they got back into the boats. He tried to stay as calm as possible. After forty minutes, he paddled his boat to the side of the river, and anchored it loosely in the reeds. He took out the satellite phone and called his wife. He told her about the tusks piercing the hull, about dangling helpless in the river, about the frantic swim to shore.
</p>


  <hr class="section-divider">
  <p>
    <em>
    Jer Thorp is an artist and educator living in Brooklyn. He is a National Geographic Emerging Explorer and a co-founder of <a href="http://o-c-r.org">The Office for Creative Research</a>. 
    </em>
  </p>
   <hr class="section-divider">
  </div>

  <div id="closing" class="graf">
  <h2>Notes</h2>
  <p>
  I love Medium. Not only do I publish a fair number of articles there, I also use it as a word processor whenever I have to write pretty much anything. My intention with this article is not to rip the Medium style, but to suggest how data elements could be added to its already excellent design for reading. 
  </p>
  <p> Many, many people have helped in the creation of the ItO API + site. Special thanks to Brian House, Shah Selbe, Ellery Royston, Ian Ardouin-Fumat and Genevieve Hoffman</p>
  <h2>Resources</h2>
  <p>
  Visit <a href="http://intotheokavango.org">intotheokavango.org</a> to explore all of the data that has come in from the field since the beginning of the expedition. Also, follow us on <a href="http://twitter.com/intotheokavango">Twitter</a> & <a href="http://instagram.com/intotheokavango">Instagram</a> for a curious mix of wildlife and data.
  </p>
  <p>
  If you're specifically interested in heartrate data, here is the API call that this example is using, which returns all of Steven's heart beats from day 68 of the expedition: <a href="http://intotheokavango.org/api/features/?FeatureType=ambit_hr&expeditionDay=68&Member=Steve">http://intotheokavango.org/api/features/?FeatureType=ambit_hr&expeditionDay=68&Member=Steve</a>
  </p>
  </p>
  All of the interactive magic here was coded in <a href="p5js.org">p5.js</a>, which is my new favourite thing.
  </p>
  </p>
  This whole article is available in all of its source-codey glory on <a href="https://github.com/blprnt/OkavangoPlayground/tree/master/OkaHeartbeat">GitHub</a>.
  </p>
  </div>
</body>
</html>